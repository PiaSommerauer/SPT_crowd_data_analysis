{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select:\n",
    "\n",
    "\n",
    "* Pairs with high agreement/few contradictions\n",
    "* Pairs with low agreement/few contradictions (if possible)\n",
    "* Pairs with high agrement/many contradictions\n",
    "* Pairs with low agreement/many contradictions\n",
    "\n",
    "Try to spread over property types\n",
    "\n",
    "\n",
    "# Annotate:\n",
    "\n",
    "* New run\n",
    "* Define new experiment group somehow\n",
    "\n",
    "# Ideas:\n",
    "\n",
    "* Low agreement, low contradiction rate: knowledge issue (some people know, some don't)\n",
    "* Low agreement, high contradiction rate: ambiguity\n",
    "\n",
    "\n",
    "\n",
    "# Implementation plan:\n",
    "\n",
    "* sort according to agreement\n",
    "* sort according to contradiction rate\n",
    "* get top pairs (top 5 or so)\n",
    "* get intersections:\n",
    "    * most problematic: low agreement - high contradiction\n",
    "    * problematic: low agreement - low contradiction\n",
    "    * interesting: high agreement - high contradiction (multiple interpretations?)\n",
    "    * clear: high agreement - low contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_experiment_data\n",
    "from calculate_iaa import get_agreement\n",
    "from utils_analysis import load_contradiction_pairs\n",
    "from utils_analysis import collect_contradictions\n",
    "from utils_analysis import sort_by_key\n",
    "from utils_analysis import get_annotation_ids\n",
    "from utils_analysis import load_analysis\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def get_agreement_by_property(data_dict_list):\n",
    "\n",
    "    agreement_prop_dict = dict()\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    for pair, dl_prop in data_by_pair.items():\n",
    "        agreement_prop_dict[pair] = get_agreement(dl_prop, v=False)\n",
    "    return agreement_prop_dict\n",
    "\n",
    "\n",
    "def get_agreement_contradiction_data(run, group, batch, n_q):\n",
    "    data_dict_list = load_experiment_data(run, group, n_q, batch, remove_not_val = True)\n",
    "    print(run, group, batch, n_q)\n",
    "    #data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    analysis_type = 'pairs'\n",
    "    df = load_analysis(analysis_type, run, group, batch)\n",
    "    pair_dicts = df.to_dict('records') \n",
    "    pair_dicts_by_pair = sort_by_key(pair_dicts, ['pair'])\n",
    "    ag_pair_dict = get_agreement_by_property(data_dict_list)\n",
    "\n",
    "    agreement_dict = Counter()\n",
    "    for pair, ag in ag_pair_dict.items():\n",
    "        agreement_dict[pair] =  ag['Krippendorff']\n",
    "\n",
    "    ag_cont_dicts = []\n",
    "    for pair, ag in agreement_dict.most_common():\n",
    "        if 'test' not in pair and 'check' not in pair: \n",
    "            d = pair_dicts_by_pair[pair]\n",
    "            if len(d) == 1:\n",
    "                new_dict = dict()\n",
    "                d = d[0]\n",
    "                #print(d.keys())\n",
    "                cont = d['contradiction_poss_contradiction_ratio']\n",
    "                new_dict['pair'] = pair\n",
    "                new_dict['agreement'] = ag\n",
    "                new_dict['contradiction_rate'] = cont\n",
    "                ag_cont_dicts.append(new_dict)\n",
    "\n",
    "            else:\n",
    "                print('unexpected length:', len(d), 'for pair', pair)\n",
    "        else:\n",
    "            print('test pair:', pair)\n",
    "        #d = data_by_pair[pair]\n",
    "    df_ag_cont = pd.DataFrame(ag_cont_dicts)\n",
    "    return df_ag_cont\n",
    "\n",
    "def get_spearman(df_cont_ag):\n",
    "    # is there a correlation between agreement and contradiction rate?\n",
    "    # we expect a negative correlation: high agreement - low contradiction\n",
    "    agreement = df_cont_ag['agreement']\n",
    "    cont = df_cont_ag['contradiction_rate']\n",
    "    spr = spearmanr(agreement, cont)\n",
    "    return spr\n",
    "\n",
    "def get_pair_sets(df_cont_ag):\n",
    "\n",
    "    pair_dict = dict()\n",
    "    df_ag_sorted = df_cont_ag.sort_values('agreement', axis = 0, ascending=False, inplace=False)\n",
    "    top_ag = df_ag_sorted[:30]\n",
    "    bottom_ag = df_ag_sorted[-30:-1]\n",
    "    df_cont_sorted = df_cont_ag.sort_values('contradiction_rate', axis = 0, ascending=False, inplace=False)\n",
    "    top_cont = df_cont_sorted[:30]\n",
    "    bottom_cont = df_cont_ag.loc[df_cont_ag['contradiction_rate'] == 0.0]\n",
    "    #df.loc[df['column_name'] == some_value]\n",
    "\n",
    "    pair_dict['low_ag_high_cont'] = set(bottom_ag['pair']).intersection(set(top_cont['pair']))\n",
    "    pair_dict['low_ag_low_cont'] = set(bottom_ag['pair']).intersection(set(bottom_cont['pair']))\n",
    "    pair_dict['high_ag_low_cont'] = set(top_ag['pair']).intersection(set(bottom_cont['pair']))\n",
    "    top_ag_sorted = top_ag.sort_values('contradiction_rate', axis = 0, ascending=False, inplace=False)\n",
    "    pair_dict['high_ag_high_cont'] = set(top_ag_sorted[:5]['pair'])\n",
    "    return pair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 655.0 annotations.\n",
      "* experiment* * *\n",
      "test pair: _check2-_check2\n",
      "test pair: _test1-_test1\n",
      "test pair: _check3-_check3\n",
      "test pair: _check1-_check1\n",
      "test pair: _test2-_test2\n",
      "test pair: _check4-_check4\n",
      "test pair: _test4-_test\n",
      "test pair: _test3-_test\n",
      "test pair: _test4-_test4\n",
      "test pair: _test3-_test3\n",
      "688\n",
      "SpearmanrResult(correlation=-0.2085848634071012, pvalue=3.351022523393455e-08)\n",
      "low_ag_high_cont\n",
      "{'square-recliner', 'fly-arrow', 'roll-shovel', 'roll-washer'}\n",
      "\n",
      "low_ag_low_cont\n",
      "{'roll-pin', 'dangerous-freebooter', 'yellow-pineapple', 'red-carrot', 'round-pen', 'yellow-leopard', 'yellow-buttercup'}\n",
      "\n",
      "high_ag_low_cont\n",
      "{'hot-vinaigrette', 'round-globe', 'sweet-cherry', 'fly-robin', 'fly-ferry', 'fly-icteridae', 'red-rhino', 'round-wheel', 'wheels-unicycle'}\n",
      "\n",
      "high_ag_high_cont\n",
      "{'roll-tyre', 'red-wine', 'sweet-candy', 'roll-tire', 'red-cherry'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run = \"*\"\n",
    "group = 'experiment*'\n",
    "batch = '*'\n",
    "n_q = '*'\n",
    "\n",
    "df_cont_ag = get_agreement_contradiction_data(run, group, batch, n_q)\n",
    "print(len(df_cont_ag))\n",
    "spr = get_spearman(df_cont_ag)\n",
    "print(spr)\n",
    "# \n",
    "pair_dict = get_pair_sets(df_cont_ag)\n",
    "for selection, pairs in pair_dict.items():\n",
    "    print(selection)\n",
    "    print(pairs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection for a trial round:\n",
    "pairs = ['fly-arrow', 'roll-pin', 'yellow-buttercup', 'hot-vineigrette', 'roll-tire']\n",
    "# write to file\n",
    "with open('../analyses/expert_inspection1.txt', 'w') as outfile:\n",
    "    for p in pairs:\n",
    "        outfile.write(p+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
