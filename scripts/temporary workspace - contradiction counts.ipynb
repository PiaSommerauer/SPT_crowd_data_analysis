{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-annotator agreement analyses\n",
    "\n",
    "\n",
    "**To do:**\n",
    "\n",
    "* Compare agreement between pairs with contradictory annotations and pairs without (of cleaned and uncleaned data)\n",
    "* Remove workers with contradictions and check fails\n",
    "* Test what happens to agreement if we collapse all annotations in a single group. \n",
    "\n",
    "**Done:**\n",
    "* Remove pair-annotations if they are contradictory [done]\n",
    "* Remove workers who fail checks [done]\n",
    "* Remove workers with high contradictions [done]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Relation evaluation:\n",
    "\n",
    "* relations with most contradictions are probably difficult\n",
    "\n",
    "## Example evaluation:\n",
    "\n",
    "* Some examples may be missleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 655.0 annotations.\n",
      "Discarded 0.0 annotations.\n",
      "Results written to: ../analyses/iaa/examples_runs3-1.csv\n"
     ]
    }
   ],
   "source": [
    "# did relation evaluation\n",
    "# ADD example evaluation\n",
    "\n",
    "\n",
    "from load_data import load_experiment_data\n",
    "from calculate_iaa import get_agreement\n",
    "from utils_analysis import load_contradiction_pairs\n",
    "from utils_analysis import collect_contradictions\n",
    "from utils_analysis import sort_by_key\n",
    "from utils_analysis import get_annotation_ids\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_agreement_by_relation(data_dict_list):\n",
    "\n",
    "    agreement_rel_dict = dict()\n",
    "    data_by_relation = sort_by_key(data_dict_list, ['relation'])\n",
    "    for rel, dl_rel in data_by_relation.items():\n",
    "        data_by_ex = sort_by_key(dl_rel, ['exampletrue', 'examplefalse'])\n",
    "        agreement_rel_dict[rel] = get_agreement(dl_rel, v=False)     \n",
    "    return agreement_rel_dict\n",
    "\n",
    "def get_agreement_by_example(data_dict_list):\n",
    "\n",
    "    agreement_ex_dict = dict()\n",
    "    relation_examples_ag_dict = dict()\n",
    "    data_by_relation = sort_by_key(data_dict_list, ['relation'])\n",
    "    for rel, dl_rel in data_by_relation.items():\n",
    "        data_by_ex = sort_by_key(dl_rel, ['exampletrue', 'examplefalse'])\n",
    "        agreement_ex_dict = dict()\n",
    "        for ex, dl_ex in data_by_ex.items():\n",
    "            agreement_ex_dict[ex] = get_agreement(dl_ex, v=False)\n",
    "            agreement_ex_dict[ex]['n_annotations'] = n_annotations = len(dl_ex)\n",
    "        relation_examples_ag_dict[rel]  = agreement_ex_dict\n",
    "    return relation_examples_ag_dict\n",
    "\n",
    "\n",
    "def agreement_relations_across_runs(runs, experiment_name):\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    batch = '*'\n",
    "    n_q = '*'\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    for run in runs:\n",
    "        data_dict_list = load_experiment_data(run, experiment_name, n_q, batch,\\\n",
    "                                              remove_not_val = True)\n",
    "        name = f'run{run}-group_{experiment_name}-batch{batch}'.replace('*', '-all-')\n",
    "        agreement_rel_dict = get_agreement_by_relation(data_dict_list)\n",
    "        run_rel_dict[run] = agreement_rel_dict\n",
    "\n",
    "    relations = set()\n",
    "    for run, rel_dict in run_rel_dict.items():\n",
    "        relations.update(rel_dict.keys())\n",
    "\n",
    "    line_dicts = []\n",
    "    for rel in relations:\n",
    "        line_dict = dict()\n",
    "        line_dict['relation'] = rel\n",
    "        for run, rel_dict in run_rel_dict.items():\n",
    "            if rel in rel_dict:\n",
    "                ag_dict = rel_dict[rel]\n",
    "                for m, ag in ag_dict.items():\n",
    "                    line_dict[f'{run}_{m}'] = ag\n",
    "        line_dicts.append(line_dict)\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    dir_name = '../analyses/iaa/'\n",
    "    f_name = f'relations_runs{\"-\".join(runs)}.csv'\n",
    "    path = f'{dir_name}{f_name}'\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    df.to_csv(path)\n",
    "    return path, df\n",
    "\n",
    "def agreement_examples_across_runs(runs, experiment_name):\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    batch = '*'\n",
    "    n_q = '*'\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    for run in runs:\n",
    "        data_dict_list = load_experiment_data(run, experiment_name, n_q, batch,\\\n",
    "                                              remove_not_val = True)\n",
    "        name = f'run{run}-group_{experiment_name}-batch{batch}'.replace('*', '-all-')\n",
    "        relation_examples_ag_dict = get_agreement_by_example(data_dict_list)\n",
    "        run_rel_dict[run] = relation_examples_ag_dict\n",
    "\n",
    "    relations = set()\n",
    "    for run, rel_dict in run_rel_dict.items():\n",
    "        relations.update(rel_dict.keys())\n",
    "\n",
    "    line_dicts = []\n",
    "    for rel in relations:\n",
    "        for run, rel_dict in run_rel_dict.items():\n",
    "            if rel in rel_dict:\n",
    "                example_ag_dict = rel_dict[rel]\n",
    "                for ex, ag_dict in example_ag_dict.items():\n",
    "                    line_dict = dict()\n",
    "                    line_dict['relation'] = rel\n",
    "                    line_dict['example'] = ex\n",
    "                    for m, ag in ag_dict.items():\n",
    "                        line_dict[f'{run}_{m}'] = ag\n",
    "                    line_dicts.append(line_dict)\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    dir_name = '../analyses/iaa/'\n",
    "    f_name = f'examples_runs{\"-\".join(runs)}.csv'\n",
    "    path = f'{dir_name}{f_name}'\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    df.to_csv(path)\n",
    "    return path, df\n",
    "\n",
    "\n",
    "def main():\n",
    "    # analyze all data:\n",
    "    runs = ['3', '1']\n",
    "    experiment_name = 'experiment1'\n",
    "    #path, df = compare_relations_across_runs(runs, experiment_name)\n",
    "    #print(f'Results written to: {path}')\n",
    "    path, df = agreement_examples_across_runs(runs, experiment_name)\n",
    "    print(f'Results written to: {path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 72\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
