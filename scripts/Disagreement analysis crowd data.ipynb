{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_experiment_data\n",
    "from calculate_iaa import get_agreement\n",
    "from utils_analysis import sort_by_key\n",
    "from utils_analysis import get_annotation_ids\n",
    "from utils_analysis import load_analysis\n",
    "from utils_analysis import load_ct\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def get_agreement_by_property(data_dict_list):\n",
    "\n",
    "    agreement_prop_dict = dict()\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    for pair, dl_prop in data_by_pair.items():\n",
    "        agreement_prop_dict[pair] = get_agreement(dl_prop, v=False, disable_kappa=True)\n",
    "    return agreement_prop_dict\n",
    "\n",
    "\n",
    "def get_pairs_by_day(data_dict_list):\n",
    "    data_by_date = sort_by_key(data_dict_list, ['timestamp'])\n",
    "    day_by_pair = dict()\n",
    "    for d, data in data_by_date.items():\n",
    "        day = d.split(' ')[0]\n",
    "        pairs = sort_by_key(data, ['property', 'concept']).keys()\n",
    "        for pair in pairs:\n",
    "            day_by_pair[pair] = day\n",
    "    return day_by_pair\n",
    "\n",
    "\n",
    "def get_agreement_contradiction_data(data_dict_list, pair_analysis, ct_dicts):\n",
    "    \n",
    "    pair_dicts = pair_analysis.to_dict('records') \n",
    "    pair_dicts_by_pair = sort_by_key(pair_dicts, ['pair'])\n",
    "    ag_pair_dict = get_agreement_by_property(data_dict_list)\n",
    "    \n",
    "    ct_by_quid = sort_by_key(ct_dicts, ['unit'])\n",
    "    # get dates\n",
    "    day_by_pair = get_pairs_by_day(data_dict_list)\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    #print(day_by_pair['round-fruit'])\n",
    "    agreement_dict = Counter()\n",
    "    for pair, ag in ag_pair_dict.items():\n",
    "        agreement_dict[pair] =  ag['Krippendorff']\n",
    "\n",
    "    ag_cont_dicts = []\n",
    "    for pair, ag in agreement_dict.most_common():\n",
    "        date = day_by_pair[pair]\n",
    "        if 'test' not in pair and 'check' not in pair: \n",
    "            d = pair_dicts_by_pair[pair]\n",
    "            annotations = data_by_pair[pair]\n",
    "            units = set([d['quid'] for d in annotations])\n",
    "            ct_dicts_units = [ct_by_quid[unit][0] for unit in units]\n",
    "            uqs_list = [d['uqs'] for d in ct_dicts_units]\n",
    "            if len(d) == 1:\n",
    "                new_dict = dict()\n",
    "                d = d[0]\n",
    "                #print(d.keys())\n",
    "                cont = d['contradiction_poss_contradiction_ratio']\n",
    "                new_dict['pair'] = pair\n",
    "                new_dict['agreement'] = ag\n",
    "                new_dict['contradiction_rate'] = cont\n",
    "                new_dict['date'] = date\n",
    "                new_dict['units'] = units\n",
    "                new_dict['uqs_list'] = uqs_list\n",
    "                new_dict['mean_uqs'] = sum(uqs_list)/len(uqs_list)\n",
    "                ag_cont_dicts.append(new_dict)\n",
    "\n",
    "            else:\n",
    "                print('unexpected length:', len(d), 'for pair', pair)\n",
    "        else:\n",
    "            print('test pair:', pair)\n",
    "        #d = data_by_pair[pair]\n",
    "    return ag_cont_dicts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 655.0 annotations.\n",
      "test pair: _test4-_test\n",
      "test pair: _check4-_check4\n",
      "test pair: _test2-_test2\n",
      "test pair: _check2-_check2\n",
      "test pair: _test1-_test1\n",
      "test pair: _test3-_test\n",
      "test pair: _check3-_check3\n",
      "test pair: _check1-_check1\n",
      "test pair: _test4-_test4\n",
      "test pair: _test3-_test3\n"
     ]
    }
   ],
   "source": [
    "run = \"*\"\n",
    "group = 'experiment*'\n",
    "batch = '*'\n",
    "n_q = '*'\n",
    "\n",
    "data_dict_list = load_experiment_data(run, group, n_q, batch, remove_not_val = True)\n",
    "analysis_type = 'pairs'\n",
    "pair_analysis =  load_analysis(analysis_type, run, group, batch)\n",
    "analysis_type = 'units'\n",
    "ct_dicts = load_ct(run, group, batch, analysis_type, as_dict=True)\n",
    "ag_cont_dicts = get_agreement_contradiction_data(data_dict_list, pair_analysis, ct_dicts)\n",
    "df_ag_cont = pd.DataFrame(ag_cont_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pairs: 1935\n"
     ]
    }
   ],
   "source": [
    "df_ag_sorted = df_ag_cont.sort_values('agreement', axis = 0, ascending=False, inplace=False)\n",
    "top_ag = df_ag_sorted[:30]\n",
    "print(f'Total number of pairs: {len(df_ag_sorted)}')\n",
    "#top_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'pair': 'made_of_wood-pen', 'agreement': 1.0, 'contradiction_rate': 0.0, 'date': '03-Jun-2020', 'units': {'39b0e894-347f-44b0-ba5a-d92cdab1b9a9', 'c657e40d-60d0-4fc3-aafc-df9320a8ec04', '5a59872e-1776-41af-afde-7c77ca860ce1', '4fe89bd2-0a76-4a72-ab9f-1879628f6188'}, 'uqs_list': [1.0, 1.0, 1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "print(type(ag_cont_dicts))\n",
    "print(ag_cont_dicts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "* CT contradictions\n",
    "* CT IAA\n",
    "* IAA contradictions\n",
    "\n",
    "\n",
    "**Results**\n",
    "* Clear high correlation between uqs and iaa (both checking the same)\n",
    "* small neg correlation between uqs and contradiction count \n",
    "* smaller neg correlation between contradiction count and iaa\n",
    "\n",
    "--> task-specific metric tests something else than traditional metrics do. It is really important to establish a quality metric independet of agreement, in particular in scenaries in which you expect the accumulated labels to approximate the truth, rather than each worker to know the truth. \n",
    "\n",
    "--> ambiguty is pervailant, but in most cases, there is an interpretation which we think is more likely than others. this is indeed shown if you use many annotators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.8436404257587673, pvalue=0.0)\n",
      "SpearmanrResult(correlation=-0.33253262649683824, pvalue=3.531225988888631e-51)\n",
      "SpearmanrResult(correlation=-0.2152463388206515, pvalue=1.0213601812316866e-21)\n"
     ]
    }
   ],
   "source": [
    "iaa = df_ag_cont['agreement']\n",
    "cont = df_ag_cont['contradiction_rate']\n",
    "uqs = df_ag_cont['mean_uqs']\n",
    "corr_uqs_iaa = spearmanr(uqs, iaa)\n",
    "corr_uqs_cont = spearmanr(uqs, cont)\n",
    "corr_cont_iaa = spearmanr(cont, iaa)\n",
    "print(corr_uqs_iaa)\n",
    "print(corr_uqs_cont)\n",
    "print(corr_cont_iaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
