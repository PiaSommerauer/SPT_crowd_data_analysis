{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_expert_data\n",
    "from load_data import load_experiment_data\n",
    "from utils_analysis import load_analysis\n",
    "from utils_analysis import sort_by_key\n",
    "#from aggregate_labels import get_top_labels\n",
    "from analyze_workers import get_worker_analysis\n",
    "from calculate_iaa import get_agreement, get_kappa_pairs\n",
    "from calculate_iaa import create_matrix\n",
    "from calculate_iaa import get_full_report\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 0.0 annotations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerid</th>\n",
       "      <th>contradiction_poss_contradiction_ratio</th>\n",
       "      <th>n_contradictions</th>\n",
       "      <th>n_fails</th>\n",
       "      <th>n_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pia_run1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antske_run1b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pia run 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Piek run-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>antske_run1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workerid  contradiction_poss_contradiction_ratio  n_contradictions  \\\n",
       "0      pia_run1                                     0.0                 0   \n",
       "1  antske_run1b                                     0.0                 0   \n",
       "2     pia run 1                                     0.0                 0   \n",
       "3    Piek run-1                                     0.0                 0   \n",
       "4   antske_run1                                     0.0                 0   \n",
       "\n",
       "   n_fails  n_annotations  \n",
       "0        0             40  \n",
       "1        0             30  \n",
       "2        0             30  \n",
       "3        0             30  \n",
       "4        0              5  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run = 4\n",
    "group = 'expert_inspection*'\n",
    "n_q = '*'\n",
    "batch = '*'\n",
    "data_dict_list = load_expert_data(run, group, n_q, batch)\n",
    "\n",
    "\n",
    "name = f'run{run}-group_{group}-batch{batch}'.replace('*', '-all-')\n",
    "df, filepath = get_worker_analysis(data_dict_list, name)\n",
    "df.drop(['annotations'], axis = 1, inplace=True)\n",
    "df[['workerid', 'contradiction_poss_contradiction_ratio', 'n_contradictions', 'n_fails', 'n_annotations']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full\n",
      "Krippendorff 0.6777142857142857\n",
      "Proportional 0.37380952380952376\n",
      "Av_Cohens_kappa 0.31293485438658614\n",
      "\n",
      "pos_neg\n",
      "Krippendorff 1.0\n",
      "Proportional 0.5\n",
      "Av_Cohens_kappa 0.5\n",
      "\n",
      "levels\n",
      "Krippendorff 1.0\n",
      "Proportional 0.4444444444444444\n",
      "Av_Cohens_kappa 0.5\n",
      "\n",
      "similar_relations\n",
      "Krippendorff 0.78\n",
      "Proportional 0.3636363636363636\n",
      "Av_Cohens_kappa 0.3954545454545455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Agreement collapsed\n",
    "\n",
    "full_report = get_full_report(data_dict_list)\n",
    "for collapsed_set, scores in full_report.items():\n",
    "    print(collapsed_set)\n",
    "    for n, s in scores.items():\n",
    "        print(n, s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement by annotator pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pia run 1', 'antske_run1b') 0.6273291925465838\n",
      "('antske_run1b', 'Piek run-1') 0.8305084745762712\n",
      "('pia run 1', 'Piek run-1') 0.6610169491525424\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matrix = create_matrix(data_dict_list)\n",
    "pair_kappa_dict = get_kappa_pairs(matrix)\n",
    "\n",
    "for pair, k in pair_kappa_dict.items():\n",
    "    if 'antske_run1' not in pair:\n",
    "        print(pair, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implied_category-roll-shovel\n",
      "typical_of_property-roll-shovel\n",
      "typical_of_concept-roll-shovel\n",
      "afforded_unusual-roll-shovel\n",
      "afforded_usual-roll-shovel\n",
      "variability_limited-roll-shovel\n",
      "creative-roll-shovel\n",
      "rare-roll-shovel\n",
      "unusual-roll-shovel\n",
      "impossible-roll-shovel\n",
      "implied_category-dangerous-freebooter\n",
      "typical_of_property-dangerous-freebooter\n",
      "typical_of_concept-dangerous-freebooter\n",
      "affording_activity-dangerous-freebooter\n",
      "variability_limited-dangerous-freebooter\n",
      "variability_open-dangerous-freebooter\n",
      "creative-dangerous-freebooter\n",
      "rare-dangerous-freebooter\n",
      "unusual-dangerous-freebooter\n",
      "impossible-dangerous-freebooter\n",
      "implied_category-yellow-pineapple\n",
      "typical_of_property-yellow-pineapple\n",
      "typical_of_concept-yellow-pineapple\n",
      "affording_activity-yellow-pineapple\n",
      "variability_limited-yellow-pineapple\n",
      "variability_open-yellow-pineapple\n",
      "creative-red-carrot\n",
      "rare-red-carrot\n",
      "unusual-red-carrot\n",
      "impossible-red-carrot\n",
      "implied_category-red-wine\n",
      "typical_of_property-red-wine\n",
      "typical_of_concept-red-wine\n",
      "affording_activity-red-wine\n",
      "variability_limited-red-wine\n",
      "variability_open-red-wine\n",
      "creative-red-wine\n",
      "rare-red-wine\n",
      "unusual-red-wine\n",
      "impossible-red-wine\n",
      "typical_of_property-fly-arrow\n",
      "typical_of_concept-fly-arrow\n",
      "afforded_usual-fly-arrow\n",
      "variability_limited-fly-arrow\n",
      "creative-fly-arrow\n",
      "rare-fly-arrow\n",
      "unusual-fly-arrow\n",
      "impossible-fly-arrow\n",
      "creative-roll-pin\n",
      "unusual-roll-pin\n",
      "impossible-roll-pin\n",
      "implied_category-yellow-buttercup\n",
      "typical_of_property-yellow-buttercup\n",
      "typical_of_concept-yellow-buttercup\n",
      "variability_limited-yellow-buttercup\n",
      "variability_open-yellow-buttercup\n",
      "typical_of_concept-roll-tire\n",
      "afforded_unusual-roll-tire\n",
      "afforded_usual-roll-tire\n",
      "variability_limited-roll-tire\n",
      "creative-roll-tire\n",
      "rare-roll-tire\n",
      "unusual-roll-tire\n",
      "impossible-roll-tire\n"
     ]
    }
   ],
   "source": [
    "report_rows = []\n",
    "data_by_pair  = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "for pair, dicts in data_by_pair.items():\n",
    "\n",
    "    relation_dicts = sort_by_key(dicts, ['relation'])\n",
    "    for rel, dicts in relation_dicts.items():\n",
    "        answers = set(d['answer'] for d in dicts if d['workerid'])\n",
    "        if len(answers) != 1:\n",
    "            for d in dicts:\n",
    "                row_d = dict()\n",
    "                row_d['triple'] = rel+'-'+pair\n",
    "                row_d['worker'] = d['workerid']\n",
    "                row_d['answer'] = d['answer']\n",
    "                #print(pair, rel, '\\t', d['workerid'], d['answer'])\n",
    "                report_rows.append(row_d)\n",
    "        else:\n",
    "            print(rel+'-'+pair)\n",
    "            #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = report_rows[0].keys()\n",
    "with open(f'../analyses/expert_annotations/report_{group}.csv', 'w') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames = header)\n",
    "    writer.writeheader()\n",
    "    for r in report_rows:\n",
    "        writer.writerow(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate expert labels\n",
    "# aggregate crowd labels \n",
    "\n",
    "# match on relation-prop-concept\n",
    "# calculate precision recall f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 655.0 annotations.\n",
      "pair in input\n",
      "found pair\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load crowd data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 0.0 annotations.\n",
      "Discarded 655.0 annotations.\n",
      "pair in input\n",
      "{'f1': 0.806, 'p': 0.8174242424242424, 'r': 0.8}\n",
      "{'f1': 0.7699248120300753, 'p': 0.8070874861572536, 'r': 0.7571428571428571}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as p_r_f1\n",
    "\n",
    "\n",
    "from load_data import load_expert_data\n",
    "from load_data import load_experiment_data\n",
    "from utils_analysis import load_analysis\n",
    "from utils_analysis import sort_by_key\n",
    "from aggregation import aggregate_binary_labels\n",
    "from clean_annotations import remove_contradicting_workers\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(expert_bin_labels, crowd_bin_labels, vote):\n",
    "    crowd_by_triple = sort_by_key(crowd_bin_labels, ['relation', 'pair'])\n",
    "    expert_by_triple = sort_by_key(expert_bin_labels, ['relation', 'pair'])\n",
    "\n",
    "    total = []\n",
    "    labels_exp = []\n",
    "    labels_crowd = []\n",
    "    for t, exp_data in expert_by_triple.items():\n",
    "        crowd_data = crowd_by_triple[t]\n",
    "        exp_answer = exp_data[0][vote]\n",
    "        crowd_answer = crowd_data[0][vote]\n",
    "        labels_exp.append(exp_answer)\n",
    "        labels_crowd.append(crowd_answer)\n",
    "    #acc = n_corr/len(total)\n",
    "    p, r, f1, support = p_r_f1(labels_exp, labels_crowd, average = 'weighted')\n",
    "    results_dict = dict()\n",
    "    results_dict['f1'] = f1\n",
    "    results_dict['p'] = p\n",
    "    results_dict['r'] = r\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "# load expert data\n",
    "run = 4\n",
    "group = 'expert_inspection*'\n",
    "n_q = '*'\n",
    "batch = '*'\n",
    "data_dict_list = load_expert_data(run, group, n_q, batch)\n",
    "\n",
    "\n",
    "# load crowd data:\n",
    "run = '*'\n",
    "group = 'experiment*'\n",
    "n_q = '*'\n",
    "batch = '*'\n",
    "data_dict_list_crowd = load_experiment_data(run, group, n_q, batch)\n",
    "# clean in preferred way: \n",
    "unit = 'pair'\n",
    "n_stds = 0.5\n",
    "if unit == 'total':\n",
    "    analysis_type = 'workers'\n",
    "else:\n",
    "    analysis_type = f'workers_by_{unit}'\n",
    "dict_list_workers = load_analysis(analysis_type, run, group, batch, as_dict = True)\n",
    "data_dict_list_crowd_clean= remove_contradicting_workers(data_dict_list_crowd, dict_list_workers, unit,  n_stds)\n",
    "\n",
    "# aggregate binary labels\n",
    "expert_bin_labels = aggregate_binary_labels(data_dict_list)\n",
    "crowd_bin_labels_raw  = aggregate_binary_labels(data_dict_list_crowd)\n",
    "crowd_bin_labels_clean  = aggregate_binary_labels(data_dict_list_crowd_clean)\n",
    "\n",
    "\n",
    "# with clean data\n",
    "results_dict = evaluate(expert_bin_labels, crowd_bin_labels_clean, vote='majority_vote')\n",
    "print(results_dict)\n",
    "\n",
    "#with raw data\n",
    "results_dict = evaluate(expert_bin_labels, crowd_bin_labels_raw, vote='majority_vote')\n",
    "print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
