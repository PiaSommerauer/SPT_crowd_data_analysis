{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_annotations import clean_workers\n",
    "from load_data import load_experiment_data, load_gold_data\n",
    "from aggregation import aggregate_binary_labels\n",
    "\n",
    "from load_data import load_experiment_data\n",
    "from calculate_iaa import get_agreement\n",
    "from utils_analysis import sort_by_key\n",
    "from utils_analysis import load_analysis, load_ct\n",
    "from utils_analysis import load_contradiction_pairs\n",
    "from utils_analysis import collect_contradictions\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as p_r_f1\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def iaa_dis_agreement(data_dict_list, expert_unit_agreement_dict):\n",
    "    \n",
    "    data_by_agreement = defaultdict(list)\n",
    "    data_by_triple = sort_by_key(data_dict_list, ['relation', 'property', 'concept'])\n",
    "    \n",
    "    for t, gold_expect in expert_unit_agreement_dict.items():\n",
    "        data = data_by_triple[t]\n",
    "        data_by_agreement[gold_expect].extend(data)\n",
    "    \n",
    "        \n",
    "    for exp, data in data_by_agreement.items():\n",
    "        agreement = get_agreement(data, v=False)\n",
    "        data_by_triple = sort_by_key(data, ['relation', 'property', 'concept'])\n",
    "        print(exp, agreement['Krippendorff'], len(data_by_triple))\n",
    "        \n",
    "\n",
    "def get_expected_behavior(gold):\n",
    "    unit_behavior_dict = dict()\n",
    "    for d in gold:\n",
    "        unit =  f\"{d['relation']}-{d['property']}-{d['concept']}\"\n",
    "        exp = d['expected_agreement']\n",
    "        if exp != 'agreement':\n",
    "            unit_behavior_dict[unit] = 'disagreement'\n",
    "        else:\n",
    "            unit_behavior_dict[unit] = 'agreement'\n",
    "    return unit_behavior_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_agreement_by_unit(data_dict_list):\n",
    "\n",
    "    agreement_unit_dict = dict()\n",
    "    data_by_unit = sort_by_key(data_dict_list, ['relation', 'property', 'concept'])\n",
    "    for unit, dl_unit in data_by_unit.items():\n",
    "        agreement = get_agreement(dl_unit, v=False, disable_kappa=True)\n",
    "        agreement_unit_dict[unit] = agreement['Proportional']\n",
    "    return agreement_unit_dict\n",
    "\n",
    "\n",
    "def get_agreement_by_pair(data_dict_list, ag_metric):\n",
    "\n",
    "    agreement_unit_dict = dict()\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    for pair, dl_unit in data_by_pair.items():\n",
    "        agreement = get_agreement(dl_unit, v=False, disable_kappa=True)\n",
    "        for d in dl_unit:\n",
    "            triple = f\"{d['relation']}-{d['property']}-{d['concept']}\"\n",
    "            agreement_unit_dict[triple] = agreement[ag_metric]\n",
    "    \n",
    "    return agreement_unit_dict\n",
    "\n",
    "def get_contradictions_by_pair(data_dict_list):\n",
    "    contradictions = load_contradiction_pairs()\n",
    "    contradictions_unit_dict = dict()\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    analysis_by_pair = sort_by_key(pair_analysis, ['pair'])\n",
    "    for pair, data_pair in data_by_pair.items():\n",
    "        data_by_worker = sort_by_key(data_pair, ['workerid'])\n",
    "        n_possible_contradictions = 0\n",
    "        n_contradictions = 0\n",
    "        for w, data in data_by_worker.items():\n",
    "            pair_worker_cont = collect_contradictions(data, contradictions, threshold = 0)\n",
    "            relations = [d['relation'] for d in data]\n",
    "            for r1, r2 in contradictions:\n",
    "                if r1 in relations and r2 in relations:\n",
    "                    n_possible_contradictions += 1\n",
    "            n_contradictions += len(pair_worker_cont)\n",
    "        relations = set([d['relation'] for d in data_pair])\n",
    "        for r in relations:\n",
    "            unit = f'{r}-{pair}'\n",
    "            if n_possible_contradictions == 0:\n",
    "                contradictions_unit_dict[unit] = 0\n",
    "            else:\n",
    "                contradictions_unit_dict[unit] = n_contradictions/n_possible_contradictions\n",
    "\n",
    "    return contradictions_unit_dict\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "def get_uqs_by_unit(data_dict_list, ct_units):\n",
    "    ct_by_unit = sort_by_key(ct_units, ['unit'])\n",
    "    uqs_unit_dict = dict()\n",
    "    for d in data_dict_list:\n",
    "        quid = d['quid']\n",
    "        if quid in ct_by_unit:\n",
    "            uqs = ct_by_unit[quid][0]['uqs']\n",
    "            triple = f\"{d['relation']}-{d['property']}-{d['concept']}\"\n",
    "            uqs_unit_dict[triple] = uqs\n",
    "    return uqs_unit_dict\n",
    "\n",
    "\n",
    "def evaluate(expert_unit_agreement_dict, crowd_data, thresh, v=True):\n",
    "    gold = []\n",
    "    predictions = []\n",
    "    correct_predictions = []\n",
    "    units_disagree = []\n",
    "    for unit, label in expert_unit_agreement_dict.items():\n",
    "        if label == 'disagreement':\n",
    "            label = 'possible_disagreement'\n",
    "        if unit in crowd_data:\n",
    "            score = crowd_data[unit]\n",
    "            if score < thresh:\n",
    "                pred = 'possible_disagreement'\n",
    "                units_disagree.append(unit)\n",
    "            else:\n",
    "                pred = 'agreement'  \n",
    "            if pred == label:\n",
    "                #print(label, pred) \n",
    "                correct_predictions.append(pred)\n",
    "            gold.append(label)\n",
    "            predictions.append(pred)\n",
    "        else:\n",
    "            pass\n",
    "            #print(unit, 'no annotations')\n",
    "    p, r, f1, support = p_r_f1(gold, predictions, average = 'weighted')\n",
    "    if v == True:\n",
    "        print('-------------------------------')\n",
    "        print('\\t gold \\t prediction \\t correct' )\n",
    "        print(\"Agreement\" ,'\\t', gold.count('agreement'),\n",
    "              '\\t', predictions.count('agreement'), '\\t', correct_predictions.count('agreement'))\n",
    "        print(\"Disagreement\",'\\t', gold.count('possible_disagreement'),\n",
    "              '\\t', predictions.count('possible_disagreement'),\n",
    "              '\\t', correct_predictions.count('possible_disagreement'))\n",
    "        print('--------------------------------')\n",
    "    print(f1, p, r)\n",
    "    return round(f1, 2), round(p, 2), round(r, 2), units_disagree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': False, 'completionurl': 'expert_annotation', 'concept': 'shovel', 'expected_agreement': 'possible_disagreement', 'property': 'roll', 'quid': 'impossible-shovel-roll', 'relation': 'impossible', 'workerid': 'gold'}\n",
      "number of gold instances:  154\n"
     ]
    }
   ],
   "source": [
    "# load expert data \n",
    "\n",
    "# load gold\n",
    "group = 'reason_agreement*_expert_inspection*'\n",
    "run = 4\n",
    "gold = load_gold_data(run, group)\n",
    "print(gold[0])\n",
    "for d in gold:\n",
    "    if 'answer' not in d:\n",
    "        print(d)\n",
    "print('number of gold instances: ', len(gold))|\n",
    "\n",
    "expert_unit_agreement_dict = get_expected_behavior(gold)\n",
    "\n",
    "\n",
    "#for k, v in expert_unit_agreement_dict.items():\n",
    " #   print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 655.0 annotations.\n"
     ]
    }
   ],
   "source": [
    "run = \"*\"\n",
    "group = 'experiment*'\n",
    "batch = '*'\n",
    "n_q = '*'\n",
    "\n",
    "analysis_type = 'units'\n",
    "ct_units = load_ct(run, group, batch, analysis_type, as_dict=True)\n",
    "\n",
    "analysis_type = 'pairs'\n",
    "pair_analysis =  load_analysis(analysis_type, run, group, batch, as_dict=True)\n",
    "\n",
    "\n",
    "crowd = load_experiment_data(run, group, n_q, batch, remove_not_val = True)\n",
    "\n",
    "run = \"*\"\n",
    "group = 'experiment*'\n",
    "batch = '*'\n",
    "n_q = '*'\n",
    "\n",
    "metric = 'contradictions'\n",
    "unit = 'batch'\n",
    "n_stdv = 0.5\n",
    "crowd_clean = clean_workers(crowd, run, group, batch, metric, unit, n_stdv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piasommerauer/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:576: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disagreement 0.13607292962181272 95\n",
      "agreement 0.25374626711976134 59\n",
      "\n",
      "disagreement 0.12686020346418592 95\n",
      "agreement 0.30297304106827916 59\n"
     ]
    }
   ],
   "source": [
    "# Agreement overview\n",
    "\n",
    "iaa_dis_agreement(crowd, expert_unit_agreement_dict)\n",
    "print()\n",
    "iaa_dis_agreement(crowd_clean, expert_unit_agreement_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.36061415493720056 0.583349486334561 0.43506493506493504\n",
      "0.5231331168831169 0.5673652190506123 0.5194805194805194\n",
      "0.6056291787939819 0.607809967031566 0.6038961038961039\n",
      "0.6190531407368142 0.6166077524194469 0.6233766233766234\n",
      "0.6377813363107481 0.6373035730833896 0.6493506493506493\n",
      "0.6193706293706295 0.6204697525655868 0.6363636363636364\n",
      "(0.64, 0.65)\n"
     ]
    }
   ],
   "source": [
    "# uqs\n",
    "\n",
    "data_uqs = get_uqs_by_unit(crowd, ct_units)\n",
    "\n",
    "threshs = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1, p, r, units_disagree_uqs = evaluate(expert_unit_agreement_dict, data_uqs, thresh, v=False)\n",
    "    f1s.append((f1, thresh))\n",
    "    #print(f1, thresh)\n",
    "print(max(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.40224027690976394 0.5879530210238871 0.45454545454545453\n",
      "0.568666766537219 0.613439590712318 0.564935064935065\n",
      "0.6206519109394855 0.6187590187590187 0.6233766233766234\n",
      "0.6153559403559404 0.6125982860676739 0.6233766233766234\n",
      "0.5859623866699338 0.587091587091587 0.6103896103896104\n",
      "0.5773325759982544 0.5782308557732286 0.6038961038961039\n",
      "(0.62, 0.6)\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 59 \t 36 \t 17\n",
      "Disagreement \t 95 \t 118 \t 76\n",
      "--------------------------------\n",
      "0.5773325759982544 0.5782308557732286 0.6038961038961039\n"
     ]
    }
   ],
   "source": [
    "# agreement per unit full\n",
    "\n",
    "\n",
    "data_ag = get_agreement_by_unit(crowd)\n",
    "\n",
    "threshs = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1, p, r, units_disagree_prop = evaluate(expert_unit_agreement_dict, data_ag, thresh, v=False)\n",
    "    f1s.append((f1, thresh))\n",
    "    #print(f1, thresh)\n",
    "print(max(f1s))   \n",
    "\n",
    "f1, p, r, units_disagree_prop_07 = evaluate(expert_unit_agreement_dict, data_ag, 0.7, v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "113\n",
      "111\n",
      "7\n",
      "---low quality annotations ---\n",
      "0.8571428571428571 7 6\n",
      "\n",
      "---- correct disagreement?---\n",
      "0.6756756756756757 111 75\n"
     ]
    }
   ],
   "source": [
    "# what is the intersection?\n",
    "\n",
    "print(len(units_disagree_prop))\n",
    "print(len(units_disagree_uqs))\n",
    "\n",
    "overlap = set(units_disagree_prop_07).intersection(set(units_disagree_uqs))\n",
    "print(len(overlap))\n",
    "\n",
    "prop_only = set(units_disagree_prop_07).difference(set(units_disagree_uqs))\n",
    "print(len(prop_only))\n",
    "\n",
    "print('---low quality annotations ---')\n",
    "labels = []\n",
    "for u in prop_only:\n",
    "    label = expert_unit_agreement_dict[u]\n",
    "    #print(u, label)\n",
    "    labels.append(label)\n",
    "acc = labels.count('agreement') / len(labels)\n",
    "print(acc, len(labels), labels.count('agreement'))\n",
    "print()\n",
    "print('---- correct disagreement?---')\n",
    "labels = []\n",
    "for u in overlap:\n",
    "    label = expert_unit_agreement_dict[u]\n",
    "    #print(u, label)\n",
    "    labels.append(label)\n",
    "acc = labels.count('disagreement')/len(labels)\n",
    "print(acc, len(labels), labels.count('disagreement'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29827320827320825 0.5263459944311009 0.4025974025974026\n",
      "0.4369235987733098 0.5522043745727956 0.461038961038961\n",
      "0.5655771595050533 0.6276365478493138 0.564935064935065\n",
      "0.6323913397084129 0.6362170815295816 0.6298701298701299\n",
      "0.643412920723845 0.6440222897669706 0.6428571428571429\n",
      "0.639534506791144 0.6375661375661376 0.6428571428571429\n",
      "0.6321892393320965 0.6299441264881205 0.6363636363636364\n",
      "(0.64, 0.65)\n"
     ]
    }
   ],
   "source": [
    "# agreement per unit clean\n",
    "\n",
    "data_ag = get_agreement_by_unit(crowd_clean)\n",
    "\n",
    "threshs = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1, p, r, units_disagree_prop = evaluate(expert_unit_agreement_dict, data_ag, thresh, v=False)\n",
    "    f1s.append((f1, thresh))\n",
    "    #print(f1, thresh)\n",
    "print(max(f1s))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.263011988011988 0.6426392399546762 0.4025974025974026\n",
      "0.2598539357041294 0.5588071838071837 0.3961038961038961\n",
      "0.2598539357041294 0.5588071838071837 0.3961038961038961\n",
      "0.29827320827320825 0.5263459944311009 0.4025974025974026\n",
      "0.4369235987733098 0.5522043745727956 0.461038961038961\n",
      "0.5655771595050533 0.6276365478493138 0.564935064935065\n",
      "(0.57, 0.5)\n"
     ]
    }
   ],
   "source": [
    "# contradiction counts full\n",
    "\n",
    "conts = get_contradictions_by_pair(crowd)\n",
    "\n",
    "threshs = [0.05, 0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1, p, r, units_disagree_prop = evaluate(expert_unit_agreement_dict, data_ag, thresh, v=False)\n",
    "    f1s.append((f1, thresh))\n",
    "    #print(f1, thresh)\n",
    "print(max(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.21224315590512774 0.1467785461291955 0.38311688311688313\n",
      "0.263011988011988 0.6426392399546762 0.4025974025974026\n",
      "0.2598539357041294 0.5588071838071837 0.3961038961038961\n",
      "0.2598539357041294 0.5588071838071837 0.3961038961038961\n",
      "0.29827320827320825 0.5263459944311009 0.4025974025974026\n",
      "0.4369235987733098 0.5522043745727956 0.461038961038961\n",
      "0.5655771595050533 0.6276365478493138 0.564935064935065\n",
      "(0.57, 0.5)\n"
     ]
    }
   ],
   "source": [
    "# contradiction counts clean\n",
    "\n",
    "conts = get_contradictions_by_pair(crowd_clean)\n",
    "\n",
    "threshs = [0.05, 0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1, p, r, units_disagree_prop = evaluate(expert_unit_agreement_dict, data_ag, thresh, v=False)\n",
    "    f1s.append((f1, thresh))\n",
    "    #print(f1, thresh)\n",
    "print(max(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6581678125795773 0.6688311688311688 0.6435732309700803\n",
      "0.6581678125795773 0.6688311688311688 0.6435732309700803\n",
      "0.6061230436230436 0.6298701298701299 0.5806185782089396\n",
      "0.6061230436230436 0.6298701298701299 0.5806185782089396\n",
      "0.48399814471243036 0.577922077922078 0.48824128363621216\n",
      "0.48399814471243036 0.577922077922078 0.48824128363621216\n",
      "0.48399814471243036 0.577922077922078 0.48824128363621216\n",
      "0.48399814471243036 0.577922077922078 0.48824128363621216\n",
      "((0.64, 0.66, 0.67), 0.45)\n"
     ]
    }
   ],
   "source": [
    "# agreement per pair full\n",
    "\n",
    "ag_metric = 'Krippendorff'\n",
    "data_ag_pair = get_agreement_by_pair(crowd, ag_metric)\n",
    "\n",
    "#threshs = [0, 0.05, 0.1, 0.15, 0.20]\n",
    "threshs = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1 = evaluate(expert_unit_agreement_dict, data_ag_pair, thresh, v=False)\n",
    "    f1s.append((f1, thresh))\n",
    "    #print(f1, thresh)\n",
    "print(max(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6581678125795773 0.6688311688311688 0.6435732309700803\n",
      "0.6581678125795773 0.6688311688311688 0.6435732309700803\n",
      "0.6581678125795773 0.6688311688311688 0.6435732309700803\n",
      "0.6581678125795773 0.6688311688311688 0.6435732309700803\n",
      "0.6061230436230436 0.6298701298701299 0.5806185782089396\n",
      "0.6061230436230436 0.6298701298701299 0.5806185782089396\n",
      "0.6061230436230436 0.6298701298701299 0.5806185782089396\n",
      "0.6061230436230436 0.6298701298701299 0.5806185782089396\n",
      "0.48399814471243036 0.577922077922078 0.48824128363621216\n",
      "0.48399814471243036 0.577922077922078 0.48824128363621216\n",
      "((0.64, 0.66, 0.67), 0.45)\n"
     ]
    }
   ],
   "source": [
    "# agreement per pair clean\n",
    "\n",
    "ag_metric = 'Krippendorff'\n",
    "data_ag_pair = get_agreement_by_pair(crowd_clean, ag_metric)\n",
    "\n",
    "#threshs = [0, 0.05, 0.1, 0.15, 0.20]\n",
    "threshs = [0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1 = evaluate(expert_unit_agreement_dict, data_ag_pair, thresh, v=False)\n",
    "    f1s.append((f1, thresh))\n",
    "    #print(f1, thresh)\n",
    "print(max(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
