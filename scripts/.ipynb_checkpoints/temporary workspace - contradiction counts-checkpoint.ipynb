{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worker evaluation and filtering\n",
    "\n",
    "* get a ranking of all workers based on contradictions and test questions \n",
    "* check test question counting code again\n",
    "* See if there is a selection of top workers and test whether they have higher agreement than the others\n",
    "* Perhaps consider putting them on a list of selected top workers with more salary\n",
    "\n",
    "\n",
    "**Note for later** Test what happens to agreement if we collapse all annotations in a single group. \n",
    "\n",
    "\n",
    "# Further steps:\n",
    "\n",
    "* add pair and relation evaluation and set up something similar to crowd truth\n",
    "\n",
    "\n",
    "## Pair evaluation: \n",
    "\n",
    "* pairs with many annotators contradicting themselves are probably difficult (likely because of polysemy)\n",
    "\n",
    "\n",
    "## Relation evaluation:\n",
    "\n",
    "* relations with most contradictions are probably difficult\n",
    "\n",
    "## Example evaluation:\n",
    "\n",
    "* Some examples may be missleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_experiment_data\n",
    "from utils_analysis import load_contradiction_pairs\n",
    "from utils_analysis import collect_contradictions\n",
    "from utils_analysis import sort_by_key\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def get_cont_type_dicts(contradictions, cont_type_cnt):\n",
    "    contradiction_dict = dict()\n",
    "    for cont in contradictions:\n",
    "        cont = tuple(sorted(cont))\n",
    "        cnt = cont_type_cnt[cont]\n",
    "        cont_str = '-'.join(cont)\n",
    "        contradiction_dict[cont_str] = cnt\n",
    "    return contradiction_dict\n",
    "\n",
    "\n",
    "def get_average_time_worker(worker_dict_list):\n",
    "\n",
    "    data_by_batch = sort_by_key(worker_dict_list, ['filename'])\n",
    "    av_time_questions = []\n",
    "    for batch, dl in data_by_batch.items():\n",
    "        # time info is the same for the entire batch\n",
    "        time = float(dl[0]['time_taken_batch'])\n",
    "        av_time_question = time / len(dl)\n",
    "        av_time_questions.append(av_time_question)\n",
    "    av_time = sum(av_time_questions) / len(av_time_questions)\n",
    "    return av_time\n",
    "\n",
    "\n",
    "def get_tests_and_checks(worker_dict_list):\n",
    "    fails = []\n",
    "    for d in worker_dict_list:\n",
    "        quid = d['quid']\n",
    "        if quid.startswith('check') or quid.startswith('test'):\n",
    "            actual_answer = d['answer']\n",
    "            if quid in ['check1', 'check2', 'check3']:\n",
    "                correct_answer = 'true'\n",
    "            elif quid.startswith('test'):\n",
    "                correct_answer = d['relation'].split('_')[1]\n",
    "            elif quid == 'check4':\n",
    "                # if quid == check4 (I am answering questions at random)\n",
    "                correct_answer = 'false'\n",
    "            #check if correct\n",
    "            if correct_answer != actual_answer:\n",
    "                worker = d['workerid']\n",
    "                fails.append(d['description'])\n",
    "    return fails\n",
    "\n",
    "\n",
    "def get_pair_analysis(data_dict_list, name):\n",
    "\n",
    "    pair_data_dicts = []\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    contradictions = load_contradiction_pairs()\n",
    "\n",
    "    for pair, dl_pair in data_by_pair.items():\n",
    "        d = dict()\n",
    "        n_annotations = len(dl_pair)\n",
    "        data_by_worker = sort_by_key(dl_pair, ['workerid'])\n",
    "        cont_cnt = Counter()\n",
    "        av_time_all_workers = []\n",
    "        d['pair'] = pair\n",
    "        workers_with_contradictions = []\n",
    "        d['n_annotations'] = n_annotations\n",
    "        n_workers = len(data_by_worker)\n",
    "        d['n_workers'] = n_workers\n",
    "        for worker, dl_worker in data_by_worker.items():\n",
    "            av_time_all_workers.append(get_average_time_worker(dl_worker))\n",
    "            pair_worker_cont = collect_contradictions(dl_worker, contradictions, threshold = 0)\n",
    "            if len(pair_worker_cont) > 0:\n",
    "                workers_with_contradictions.append(worker)\n",
    "            cont_cnt.update(pair_worker_cont)\n",
    "        n_contradictions = sum(cont_cnt.values())\n",
    "        d['n_contradictions'] = n_contradictions\n",
    "        d['n_workers_contradicting'] = len(workers_with_contradictions)\n",
    "        d['ratio_workers_contradicting'] = len(workers_with_contradictions)/n_workers\n",
    "        d['contradiction_annotation_ratio'] = n_contradictions/n_annotations\n",
    "        d['average_time_pair'] = sum(av_time_all_workers)/len(av_time_all_workers)\n",
    "        d['workers_contradicting'] = ' '.join(workers_with_contradictions)\n",
    "        workers_not_contradicting = [w for w in data_by_worker if w \\\n",
    "                                     not in workers_with_contradictions]\n",
    "        d['workers_not_contradicting'] = ' '.join(workers_not_contradicting)\n",
    "        # add contradiction_type analysis\n",
    "        d.update(cont_cnt)\n",
    "        pair_data_dicts.append(d)\n",
    "\n",
    "    pair_df = pd.DataFrame(pair_data_dicts)\n",
    "    # sort by contradiction to annotation ratio\n",
    "    pair_df.sort_values('contradiction_annotation_ratio', axis=0, ascending=False, inplace=True)\n",
    "    out_dir = '../analyses/pairs/'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    filepath = f'{out_dir}{name}.csv'\n",
    "    pair_df.to_csv(filepath)\n",
    "    return pair_df, filepath\n",
    "\n",
    "def show_pairs_of_worker(worker, df):\n",
    "    print(f'Worker {worker} contradicted themselves in the following pairs:')\n",
    "    print()\n",
    "    for ind, row in df.iterrows():\n",
    "        workers_cont = row['workers_contradicting'].split(' ')\n",
    "        if worker in workers_cont:\n",
    "            pair = row['pair']\n",
    "            print(f'{pair} \\t total workers contradicting themselves: {len(workers_cont)}')\n",
    "\n",
    "\n",
    "\n",
    "def get_ratio_contradicting_pair_annotations(df):\n",
    "\n",
    "    n_worker_pairs_total = 0.0\n",
    "    n_worker_pairs_contradicting = 0.0\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        n_worker_pairs_total += row['n_workers']\n",
    "        n_worker_pairs_contradicting += row['n_workers_contradicting']\n",
    "\n",
    "    if n_worker_pairs_contradicting != 0:\n",
    "        ratio = n_worker_pairs_contradicting / n_worker_pairs_total\n",
    "    else:\n",
    "        ratio = 0.0\n",
    "    return ratio\n",
    "\n",
    "\n",
    "\n",
    "def comparison_general(name1, name2, df1, df2):\n",
    "\n",
    "    ratio1 = get_ratio_contradicting_pair_annotations(df1)\n",
    "    ratio2 = get_ratio_contradicting_pair_annotations(df2)\n",
    "\n",
    "    print(f'Set {name1} as a contradiction ratio of {ratio1}')\n",
    "    print(f'Set {name2} as a contradiction ratio of {ratio2}')\n",
    "    print('The ratio is based on the number of workers annotating a pair.')\n",
    "    print('A worker always annotates a full set.')\n",
    "    return ratio1, ratio2\n",
    "\n",
    "def comparison_matching_pairs(name1, name2, df1, df2):\n",
    "\n",
    "    # get overlapping pairs\n",
    "    pairs_df1 = set([row['pair'] for ind, row in df1.iterrows()])\n",
    "    pairs_df2 = set([row['pair'] for ind, row in df2.iterrows()])\n",
    "    shared_pairs = pairs_df1.intersection(pairs_df2)\n",
    "\n",
    "    rows_df1_clean = [row for ind, row in df1.iterrows() if row['pair'] in shared_pairs]\n",
    "    rows_df2_clean = [row for ind, row in df2.iterrows() if row['pair'] in shared_pairs]\n",
    "\n",
    "    df1_clean = pd.DataFrame(rows_df1_clean)\n",
    "    df2_clean = pd.DataFrame(rows_df2_clean)\n",
    "\n",
    "    #df_add_row = df_merge_col.append(add_row, ignore_index=True)\n",
    "    ratio1, ratio2 = comparison_general(name1, name2, df1_clean, df2_clean)\n",
    "    print(f'This analysis only includes pairs annotated in run {name1} and run {name2}.')\n",
    "    return ratio1, ratio2\n",
    "\n",
    "def compare_runs(name1, name2, df1, df2, comp = 'all'):\n",
    "    if comp == 'all':\n",
    "        r1, r2 = comparison_general(name1, name2, df1, df2)\n",
    "    elif comp == 'pairs':\n",
    "        r1, r2 = comparison_matching_pairs(name1, name2, df1, df2)\n",
    "    return r1, r2\n",
    "\n",
    "\n",
    "def main():\n",
    "    # analyze all data:\n",
    "    run = '3'\n",
    "    batch = '16'\n",
    "    n_q = '*'\n",
    "    group = 'experiment1'\n",
    "\n",
    "    data_dict_list = load_experiment_data(run, group, n_q, batch, remove_not_val = True)\n",
    "    name = f'run{run}-group_{group}-batch{batch}'.replace('*', '-all-')\n",
    "    df, filepath = get_pair_analysis(data_dict_list, name)\n",
    "    print(f'analysis can be found at: {filepath}')\n",
    "\n",
    "    run = '1'\n",
    "    batch = '*'\n",
    "    n_q = '*'\n",
    "    group = 'experiment1'\n",
    "\n",
    "    data_dict_list = load_experiment_data(run, group, n_q, batch, remove_not_val = True)\n",
    "    name = f'run{run}-group_{group}-batch{batch}'.replace('*', '-all-')\n",
    "    df1, filepath = get_pair_analysis(data_dict_list, name)\n",
    "    print(f'analysis can be found at: {filepath}')\n",
    "\n",
    "    run = '3'\n",
    "    batch = '*'\n",
    "    n_q = '*'\n",
    "    group = 'experiment1'\n",
    "\n",
    "    data_dict_list = load_experiment_data(run, group, n_q, batch, remove_not_val = True)\n",
    "    name = f'run{run}-group_{group}-batch{batch}'.replace('*', '-all-')\n",
    "    df2, filepath = get_pair_analysis(data_dict_list, name)\n",
    "    print(f'analysis can be found at: {filepath}')\n",
    "\n",
    "    name1 = '1'\n",
    "    name2 = '3'\n",
    "    compare_runs(name1, name2, df1, df2, comp = 'all')\n",
    "    print()\n",
    "    compare_runs(name1, name2, df1, df2, comp = 'pairs')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
