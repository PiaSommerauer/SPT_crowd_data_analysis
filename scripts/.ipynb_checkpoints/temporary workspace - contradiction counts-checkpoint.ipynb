{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-annotator agreement analyses\n",
    "\n",
    "\n",
    "**To do:**\n",
    "\n",
    "* Compare agreement between pairs with contradictory annotations and pairs without (of cleaned and uncleaned data)\n",
    "* Remove workers with contradictions and check fails\n",
    "* Test what happens to agreement if we collapse all annotations in a single group. \n",
    "\n",
    "**Done:**\n",
    "* Remove pair-annotations if they are contradictory [done]\n",
    "* Remove workers who fail checks [done]\n",
    "* Remove workers with high contradictions [done]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Relation evaluation:\n",
    "\n",
    "* relations with most contradictions are probably difficult\n",
    "\n",
    "## Example evaluation:\n",
    "\n",
    "* Some examples may be missleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did relation evaluation\n",
    "# ADD example evaluation\n",
    "\n",
    "\n",
    "from load_data import load_experiment_data\n",
    "from calculate_iaa import get_agreement\n",
    "from utils_analysis import load_contradiction_pairs\n",
    "from utils_analysis import collect_contradictions\n",
    "from utils_analysis import sort_by_key\n",
    "from utils_analysis import get_annotation_ids\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_agreement_by_relation(data_dict_list):\n",
    "\n",
    "    agreement_rel_dict = dict()\n",
    "    data_by_relation = sort_by_key(data_dict_list, ['relation'])\n",
    "    for rel, dl_rel in data_by_relation.items():\n",
    "        data_by_ex = sort_by_key(dl_rel, ['exampletrue', 'examplefalse'])\n",
    "        agreement_rel_dict[rel] = get_agreement(dl_rel, v=False)     \n",
    "    return agreement_rel_dict\n",
    "\n",
    "def get_agreement_by_example(data_dict_list):\n",
    "\n",
    "    agreement_ex_dict = dict()\n",
    "    relation_examples_dict = dict()\n",
    "    data_by_relation = sort_by_key(data_dict_list, ['relation'])\n",
    "    for rel, dl_rel in data_by_relation.items():\n",
    "        data_by_ex = sort_by_key(dl_rel, ['exampletrue', 'examplefalse'])\n",
    "        agreement_rel_dict[rel] = get_agreement(dl_rel, v=False)\n",
    "        for ex, dl_ex in data_by_ex.items():\n",
    "            agreement_ex_dict[ex] = get_agreement(dl_ex, v=False)\n",
    "        relation_examples_dict[rel] = agreement_examples_dict\n",
    "    return agreement_ex_dict, relation_examples_dict\n",
    "\n",
    "\n",
    "def agreement_relations_across_runs(runs, experiment_name):\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    batch = '*'\n",
    "    n_q = '*'\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    for run in runs:\n",
    "        data_dict_list = load_experiment_data(run, experiment_name, n_q, batch,\\\n",
    "                                              remove_not_val = True)\n",
    "        name = f'run{run}-group_{experiment_name}-batch{batch}'.replace('*', '-all-')\n",
    "        agreement_rel_dict = get_agreement_by_relation(data_dict_list)\n",
    "        run_rel_dict[run] = agreement_rel_dict\n",
    "\n",
    "    relations = set()\n",
    "    for run, rel_dict in run_rel_dict.items():\n",
    "        relations.update(rel_dict.keys())\n",
    "\n",
    "    line_dicts = []\n",
    "    for rel in relations:\n",
    "        line_dict = dict()\n",
    "        line_dict['relation'] = rel\n",
    "        for run, rel_dict in run_rel_dict.items():\n",
    "            if rel in rel_dict:\n",
    "                ag_dict = rel_dict[rel]\n",
    "                for m, ag in ag_dict.items():\n",
    "                    line_dict[f'{run}_{m}'] = ag\n",
    "        line_dicts.append(line_dict)\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    dir_name = '../analyses/iaa/'\n",
    "    f_name = f'relations_runs{\"-\".join(runs)}.csv'\n",
    "    path = f'{dir_name}{f_name}'\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    df.to_csv(path)\n",
    "    return path, df\n",
    "\n",
    "def agreement_examples_across_runs(runs, experiment_name):\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    batch = '*'\n",
    "    n_q = '*'\n",
    "\n",
    "    run_rel_dict = dict()\n",
    "    for run in runs:\n",
    "        data_dict_list = load_experiment_data(run, experiment_name, n_q, batch,\\\n",
    "                                              remove_not_val = True)\n",
    "        name = f'run{run}-group_{experiment_name}-batch{batch}'.replace('*', '-all-')\n",
    "        agreement_rel_dict = get_agreement_by_relation(data_dict_list)\n",
    "        run_rel_dict[run] = agreement_rel_dict\n",
    "\n",
    "    relations = set()\n",
    "    for run, rel_dict in run_rel_dict.items():\n",
    "        relations.update(rel_dict.keys())\n",
    "\n",
    "    line_dicts = []\n",
    "    for rel in relations:\n",
    "        line_dict = dict()\n",
    "        line_dict['relation'] = rel\n",
    "        for run, rel_dict in run_rel_dict.items():\n",
    "            if rel in rel_dict:\n",
    "                ag_dict = rel_dict[rel]\n",
    "                for m, ag in ag_dict.items():\n",
    "                    line_dict[f'{run}_{m}'] = ag\n",
    "        line_dicts.append(line_dict)\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    dir_name = '../analyses/iaa/'\n",
    "    f_name = f'relations_runs{\"-\".join(runs)}.csv'\n",
    "    path = f'{dir_name}{f_name}'\n",
    "    df = pd.DataFrame(line_dicts)\n",
    "    df.to_csv(path)\n",
    "    return path, df\n",
    "\n",
    "\n",
    "def main():\n",
    "    # analyze all data:\n",
    "    runs = ['3', '1']\n",
    "    experiment_name = 'experiment1'\n",
    "    #path, df = compare_relations_across_runs(runs, experiment_name)\n",
    "    #print(f'Results written to: {path}')\n",
    "    run = 3\n",
    "    n_q = '*'\n",
    "    batch = '*'\n",
    "    data_dict_list = load_experiment_data(run, experiment_name, n_q, batch,\\\n",
    "                                              remove_not_val = True)\n",
    "    get_agreement_by_example(data_dict_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for updating examples\n",
    "\n",
    "* Temporary - needs better structure and doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_analysis import sort_by_key\n",
    "import csv\n",
    "from collections import defaultdict \n",
    "\n",
    "run = 3\n",
    "batch = 25\n",
    "n_q = 70\n",
    "group = 'experiment1'\n",
    "\n",
    "output_path = '../data/prolific_output/run3-group_experiment1/qu70-s_qu70-batch25.csv'\n",
    "input_path = '../../SPT_annotation/prolific_input/run3-group_experiment1/qu70-s_qu70-batch25.csv'\n",
    "header = ['quid', 'description', 'exampleTrue',\\\n",
    "          'exampleFalse', 'run', 'subList', 'triple', 'triple', 'url']\n",
    "with open(output_path) as infile:\n",
    "    dict_list_output = list(csv.DictReader(infile))\n",
    "    \n",
    "    \n",
    "with open(input_path) as infile:\n",
    "    dict_list_input = list(csv.DictReader(infile, fieldnames = header))\n",
    "    \n",
    "input_by_quid = sort_by_key(dict_list_input, ['quid'])  \n",
    "output_by_quid = sort_by_key(dict_list_output, ['quid'])\n",
    "print(len(input_by_quid), len(output_by_quid))\n",
    "\n",
    "\n",
    "for d in dict_list_output:\n",
    "    quid = d['quid']\n",
    "    d_input = input_by_quid[quid][0]\n",
    "    triple = d_input['triple']\n",
    "    #print(d['description'])\n",
    "    #print(quid, triple)\n",
    "    d['triple'] = triple  \n",
    "    \n",
    "    \n",
    "# to file \n",
    "output_path = '../data/prolific_output/run3-group_experiment1/qu70-s_qu70-batch25.csv'\n",
    "\n",
    "fieldnames = dict_list_output[0].keys()\n",
    "with open(output_path, 'w') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "    for d in dict_list_output:\n",
    "        writer.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 72\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
