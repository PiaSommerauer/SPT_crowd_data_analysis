{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_annotations import clean_workers\n",
    "from load_data import load_experiment_data, load_expert_data, load_gold_data\n",
    "from aggregation import aggregate_binary_labels\n",
    "\n",
    "from load_data import load_experiment_data\n",
    "from calculate_iaa import get_agreement\n",
    "from utils_analysis import sort_by_key\n",
    "from utils_analysis import load_analysis, load_ct\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as p_r_f1\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def iaa_dis_agreement(data_dict_list, expert_unit_agreement_dict):\n",
    "    \n",
    "    data_by_agreement = defaultdict(list)\n",
    "    data_by_triple = sort_by_key(data_dict_list, ['relation', 'property', 'concept'])\n",
    "    \n",
    "    for t, gold_expect in expert_unit_agreement_dict.items():\n",
    "        data = data_by_triple[t]\n",
    "        print(t, gold_expect)\n",
    "        data_by_agreement[gold_expect].extend(data)\n",
    "        \n",
    "    for exp, data in data_by_agreement.items():\n",
    "        #print(exp)\n",
    "        agreement = get_agreement(data, v=False)\n",
    "        print(exp, agreement['Krippendorff'])\n",
    "        \n",
    "\n",
    "def get_expert_agreement_labels(expert_annotations):\n",
    "    expert_annotations_by_unit = sort_by_key(expert_annotations, ['relation',\n",
    "                                                              'property', 'concept'])\n",
    "    unit_agreement_dict = dict()\n",
    "    for unit, data in expert_annotations_by_unit.items():\n",
    "        agreements = []\n",
    "        for d in data:\n",
    "            w = d['workerid']\n",
    "            if not w.endswith('_test1'):\n",
    "                for k in d.keys():\n",
    "                    #print(k)\n",
    "                    if k.startswith('disagreement_'):\n",
    "                        agreements.append(k)\n",
    "        n_agreement_annotations = len(agreements)\n",
    "        n_agree = agreements.count('disagreement_agreement')\n",
    "        prop_agreement = n_agree/n_agreement_annotations\n",
    "\n",
    "        if prop_agreement == 1.0:\n",
    "            unit_agreement_dict[unit] = 'agreement'\n",
    "        elif 'disagreement_agreement' in agreements:\n",
    "            unit_agreement_dict[unit] = 'possible_disagreement'\n",
    "        else:\n",
    "            unit_agreement_dict[unit] = 'disagreement'\n",
    "    return unit_agreement_dict\n",
    "\n",
    "\n",
    "def get_agreement_by_unit(data_dict_list):\n",
    "\n",
    "    agreement_unit_dict = dict()\n",
    "    data_by_unit = sort_by_key(data_dict_list, ['relation', 'property', 'concept'])\n",
    "    for unit, dl_unit in data_by_unit.items():\n",
    "        agreement = get_agreement(dl_unit, v=False, disable_kappa=True)\n",
    "        agreement_unit_dict[unit] = agreement['Proportional']\n",
    "    return agreement_unit_dict\n",
    "\n",
    "\n",
    "def get_agreement_by_pair(data_dict_list, ag_metric):\n",
    "\n",
    "    agreement_unit_dict = dict()\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    for pair, dl_unit in data_by_pair.items():\n",
    "        agreement = get_agreement(dl_unit, v=False, disable_kappa=True)\n",
    "        for d in dl_unit:\n",
    "            triple = f\"{d['relation']}-{d['property']}-{d['concept']}\"\n",
    "            agreement_unit_dict[triple] = agreement[ag_metric]\n",
    "    \n",
    "    return agreement_unit_dict\n",
    "\n",
    "def get_contradictions_by_pair(data_dict_list, pair_analysis):\n",
    "    \n",
    "    contradictions_unit_dict = dict()\n",
    "    data_by_pair = sort_by_key(data_dict_list, ['property', 'concept'])\n",
    "    analysis_by_pair = sort_by_key(pair_analysis, ['pair'])\n",
    "    for pair, data in data_by_pair.items():\n",
    "        analysis = analysis_by_pair[pair][0]\n",
    "        n_workers = analysis['n_workers']\n",
    "        n_workers_contradicting = analysis['n_workers_contradicting']\n",
    "        ratio = n_workers_contradicting/n_workers\n",
    "        for d in data:\n",
    "            triple = f\"{d['relation']}-{d['property']}-{d['concept']}\"\n",
    "            contradictions_unit_dict[triple] = ratio\n",
    "    return contradictions_unit_dict\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "def get_uqs_by_unit(data_dict_list, ct_units):\n",
    "    ct_by_unit = sort_by_key(ct_units, ['unit'])\n",
    "    uqs_unit_dict = dict()\n",
    "    for d in data_dict_list:\n",
    "        quid = d['quid']\n",
    "        if quid in ct_by_unit:\n",
    "            uqs = ct_by_unit[quid][0]['uqs']\n",
    "            triple = f\"{d['relation']}-{d['property']}-{d['concept']}\"\n",
    "            uqs_unit_dict[triple] = uqs\n",
    "    return uqs_unit_dict\n",
    "\n",
    "\n",
    "def evaluate(expert_unit_agreement_dict, crowd_data, thresh, v=True):\n",
    "    gold = []\n",
    "    predictions = []\n",
    "    correct_predictions = []\n",
    "    for unit, label in expert_unit_agreement_dict.items():\n",
    "        if unit in crowd_data:\n",
    "            score = crowd_data[unit]\n",
    "            if score < thresh:\n",
    "                pred = 'possible_disagreement'\n",
    "            else:\n",
    "                pred = 'agreement'  \n",
    "            if pred == label:\n",
    "                #print(label, pred) \n",
    "                correct_predictions.append(pred)\n",
    "            gold.append(label)\n",
    "            predictions.append(pred)\n",
    "        else:\n",
    "            pass\n",
    "            #print(unit, 'no annotations')\n",
    "    p, r, f1, support = p_r_f1(gold, predictions, average = 'weighted')\n",
    "    if v == True:\n",
    "        print('-------------------------------')\n",
    "        print('\\t gold \\t prediction \\t correct' )\n",
    "        print(\"Agreement\" ,'\\t', gold.count('agreement'),\n",
    "              '\\t', predictions.count('agreement'), '\\t', correct_predictions.count('agreement'))\n",
    "        print(\"Disagreement\",'\\t', gold.count('possible_disagreement'),\n",
    "              '\\t', predictions.count('possible_disagreement'),\n",
    "              '\\t', correct_predictions.count('possible_disagreement'))\n",
    "        print('--------------------------------')\n",
    "        print(p, r, f1)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run4-group_reason_agreement_expert_inspection2/qu40-s_qu40-batch1.csv\n",
      "no summary data\n",
      "run4-group_reason_agreement_expert_inspection3/qu40-s_qu40-batch1.csv\n",
      "no summary data\n",
      "run4-group_reason_agreement_expert_inspection1/qu30-s_qu30-batch1.csv\n",
      "no summary data\n"
     ]
    }
   ],
   "source": [
    "# load expert data \n",
    "\n",
    "run = \"4\"\n",
    "#group1 = 'reason_agreement_expert_inspection1'\n",
    "group = 'reason_agreement_expert_inspection*'\n",
    "batch = '*'\n",
    "n_q = '*'\n",
    "\n",
    "#run4-group_reason_agreement_expert_inspection1\n",
    "expert_annotations = load_expert_data(run, group, n_q, batch)\n",
    "#expert_annotations2 = load_expert_data(run, group2, n_q, batch)\n",
    "#expert_annotations = expert_annotations1 + expert_annotations2\n",
    "#expert_unit_agreement_dict = get_expert_agreement_labels(expert_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 655.0 annotations.\n"
     ]
    }
   ],
   "source": [
    "run = \"*\"\n",
    "group = 'experiment*'\n",
    "batch = '*'\n",
    "n_q = '*'\n",
    "\n",
    "analysis_type = 'units'\n",
    "ct_units = load_ct(run, group, batch, analysis_type, as_dict=True)\n",
    "\n",
    "analysis_type = 'pairs'\n",
    "pair_analysis =  load_analysis(analysis_type, run, group, batch, as_dict=True)\n",
    "\n",
    "\n",
    "data_dict_list = load_experiment_data(run, group, n_q, batch, remove_not_val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement\n",
      "agreement 0.2427437367364772\n",
      "possible_disagreement\n",
      "possible_disagreement 0.026575395486579945\n",
      "disagreement\n",
      "disagreement 0.0\n"
     ]
    }
   ],
   "source": [
    "# Agreement overview\n",
    "\n",
    "iaa_dis_agreement(data_dict_list, expert_unit_agreement_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 57 \t 32\n",
      "Disagreement \t 25 \t 0 \t 0\n",
      "--------------------------------\n",
      "0.3151738996614343 0.5614035087719298 0.40370589394835404\n",
      "0.40370589394835404 0.4\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 46 \t 30\n",
      "Disagreement \t 25 \t 11 \t 9\n",
      "--------------------------------\n",
      "0.7249843977532766 0.6842105263157895 0.6511470985155196\n",
      "0.6511470985155196 0.45\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 30 \t 22\n",
      "Disagreement \t 25 \t 27 \t 17\n",
      "--------------------------------\n",
      "0.6878492527615334 0.6842105263157895 0.6851900222019068\n",
      "0.6851900222019068 0.5\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 22 \t 19\n",
      "Disagreement \t 25 \t 35 \t 22\n",
      "--------------------------------\n",
      "0.760537707906129 0.7192982456140351 0.7166991552956465\n",
      "0.7166991552956465 0.55\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 18 \t 16\n",
      "Disagreement \t 25 \t 39 \t 23\n",
      "--------------------------------\n",
      "0.7576848103163892 0.6842105263157895 0.6745394736842106\n",
      "0.6745394736842106 0.6\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 16 \t 14\n",
      "Disagreement \t 25 \t 41 \t 23\n",
      "--------------------------------\n",
      "0.7372700042789901 0.6491228070175439 0.6331738437001595\n",
      "0.6331738437001595 0.65\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 15 \t 13\n",
      "Disagreement \t 25 \t 42 \t 23\n",
      "--------------------------------\n",
      "0.7267335004177109 0.631578947368421 0.611689592351791\n",
      "0.611689592351791 0.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_uqs = get_uqs_by_unit(data_dict_list, ct_units)\n",
    "\n",
    "threshs = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1 = evaluate(expert_unit_agreement_dict, data_uqs, thresh, v=True)\n",
    "    f1s.append(f1)\n",
    "    print(f1, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 57 \t 32\n",
      "Disagreement \t 25 \t 0 \t 0\n",
      "--------------------------------\n",
      "0.3151738996614343 0.5614035087719298 0.40370589394835404\n",
      "0.40370589394835404 0.4\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 46 \t 30\n",
      "Disagreement \t 25 \t 11 \t 9\n",
      "--------------------------------\n",
      "0.7249843977532766 0.6842105263157895 0.6511470985155196\n",
      "0.6511470985155196 0.45\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 32 \t 24\n",
      "Disagreement \t 25 \t 25 \t 17\n",
      "--------------------------------\n",
      "0.7192982456140351 0.7192982456140351 0.7192982456140351\n",
      "0.7192982456140351 0.5\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 20 \t 17\n",
      "Disagreement \t 25 \t 37 \t 22\n",
      "--------------------------------\n",
      "0.7379800853485065 0.6842105263157895 0.6783335509990857\n",
      "0.6783335509990857 0.55\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 17 \t 14\n",
      "Disagreement \t 25 \t 40 \t 22\n",
      "--------------------------------\n",
      "0.7035603715170279 0.631578947368421 0.6176980913823019\n",
      "0.6176980913823019 0.6\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 13 \t 12\n",
      "Disagreement \t 25 \t 44 \t 24\n",
      "--------------------------------\n",
      "0.7574530732425468 0.631578947368421 0.6045258072718027\n",
      "0.6045258072718027 0.65\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 12 \t 11\n",
      "Disagreement \t 25 \t 45 \t 24\n",
      "--------------------------------\n",
      "0.7485380116959064 0.6140350877192983 0.5814536340852131\n",
      "0.5814536340852131 0.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_ag = get_agreement_by_unit(data_dict_list)\n",
    "\n",
    "threshs = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1 = evaluate(expert_unit_agreement_dict, data_ag, thresh, v=True)\n",
    "    f1s.append(f1)\n",
    "    print(f1, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 34 \t 22\n",
      "Disagreement \t 25 \t 23 \t 13\n",
      "--------------------------------\n",
      "0.6111634585184189 0.6140350877192983 0.6118421052631579\n",
      "0.6118421052631579 0.05\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 34 \t 22\n",
      "Disagreement \t 25 \t 23 \t 13\n",
      "--------------------------------\n",
      "0.6111634585184189 0.6140350877192983 0.6118421052631579\n",
      "0.6118421052631579 0.1\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 34 \t 22\n",
      "Disagreement \t 25 \t 23 \t 13\n",
      "--------------------------------\n",
      "0.6111634585184189 0.6140350877192983 0.6118421052631579\n",
      "0.6118421052631579 0.15\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 34 \t 22\n",
      "Disagreement \t 25 \t 23 \t 13\n",
      "--------------------------------\n",
      "0.6111634585184189 0.6140350877192983 0.6118421052631579\n",
      "0.6118421052631579 0.2\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 24 \t 15\n",
      "Disagreement \t 25 \t 33 \t 16\n",
      "--------------------------------\n",
      "0.5635300372142478 0.543859649122807 0.5427361507216316\n",
      "0.5427361507216316 0.25\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 16 \t 8\n",
      "Disagreement \t 25 \t 41 \t 17\n",
      "--------------------------------\n",
      "0.46255883611467696 0.43859649122807015 0.4130781499202552\n",
      "0.4130781499202552 0.3\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 16 \t 8\n",
      "Disagreement \t 25 \t 41 \t 17\n",
      "--------------------------------\n",
      "0.46255883611467696 0.43859649122807015 0.4130781499202552\n",
      "0.4130781499202552 0.35\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 16 \t 8\n",
      "Disagreement \t 25 \t 41 \t 17\n",
      "--------------------------------\n",
      "0.46255883611467696 0.43859649122807015 0.4130781499202552\n",
      "0.4130781499202552 0.4\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 16 \t 8\n",
      "Disagreement \t 25 \t 41 \t 17\n",
      "--------------------------------\n",
      "0.46255883611467696 0.43859649122807015 0.4130781499202552\n",
      "0.4130781499202552 0.45\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 16 \t 8\n",
      "Disagreement \t 25 \t 41 \t 17\n",
      "--------------------------------\n",
      "0.46255883611467696 0.43859649122807015 0.4130781499202552\n",
      "0.4130781499202552 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_cont = get_contradictions_by_pair(data_dict_list, pair_analysis)\n",
    "\n",
    "threshs = [0.1, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1 = evaluate(expert_unit_agreement_dict, data_cont, thresh, v=True)\n",
    "    f1s.append(f1)\n",
    "    print(f1, thresh)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 57 \t 32\n",
      "Disagreement \t 25 \t 0 \t 0\n",
      "--------------------------------\n",
      "0.3151738996614343 0.5614035087719298 0.40370589394835404\n",
      "0.40370589394835404 0.4\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 57 \t 32\n",
      "Disagreement \t 25 \t 0 \t 0\n",
      "--------------------------------\n",
      "0.3151738996614343 0.5614035087719298 0.40370589394835404\n",
      "0.40370589394835404 0.45\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 21 \t 16\n",
      "Disagreement \t 25 \t 36 \t 20\n",
      "--------------------------------\n",
      "0.6714007240323029 0.631578947368421 0.6265648656128413\n",
      "0.6265648656128413 0.5\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 18 \t 14\n",
      "Disagreement \t 25 \t 39 \t 21\n",
      "--------------------------------\n",
      "0.6728145149197782 0.6140350877192983 0.6022149122807018\n",
      "0.6022149122807018 0.55\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 18 \t 14\n",
      "Disagreement \t 25 \t 39 \t 21\n",
      "--------------------------------\n",
      "0.6728145149197782 0.6140350877192983 0.6022149122807018\n",
      "0.6022149122807018 0.6\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 18 \t 14\n",
      "Disagreement \t 25 \t 39 \t 21\n",
      "--------------------------------\n",
      "0.6728145149197782 0.6140350877192983 0.6022149122807018\n",
      "0.6022149122807018 0.65\n",
      "\n",
      "-------------------------------\n",
      "\t gold \t prediction \t correct\n",
      "Agreement \t 32 \t 18 \t 14\n",
      "Disagreement \t 25 \t 39 \t 21\n",
      "--------------------------------\n",
      "0.6728145149197782 0.6140350877192983 0.6022149122807018\n",
      "0.6022149122807018 0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ag_metric = 'Proportional'\n",
    "data_ag_pair = get_agreement_by_pair(data_dict_list, ag_metric)\n",
    "\n",
    "#threshs = [0, 0.05, 0.1, 0.15, 0.20]\n",
    "threshs = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "f1s = []\n",
    "for thresh in threshs:\n",
    "    f1 = evaluate(expert_unit_agreement_dict, data_ag_pair, thresh, v=True)\n",
    "    f1s.append(f1)\n",
    "    print(f1, thresh)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
